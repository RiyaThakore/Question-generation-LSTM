{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question generation(A1).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcw8OLny2W7w0tyF8obONF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiyaThakore/Question-generation-LSTM/blob/master/Question_generation(A1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCyusM1wJVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "  \n",
        "df = getDF('/content/sample_data/qa_Appliances.json.gz')\n",
        "#df = df.drop(['questionType', 'asin', 'answerTime', 'unixTime','answerType'], axis = 1)\n",
        "a = df.to_csv('/content/sample_data/appliances.csv')\n",
        "data = pd.read_csv(\"/content/sample_data/appliances.csv\") \n",
        "\n",
        "def display_char_vocab(data):\n",
        "  chars = sorted(list(set(data)))\n",
        "  #char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "  n_chars = len(data)\n",
        "  n_vocab = len(chars)\n",
        "  return n_chars, n_vocab\n",
        "\n",
        "seq_length = 100\n",
        "#h = df.head()\n",
        "#print(h)\n",
        "#print(df.columns)\n",
        "y = data.question\n",
        "X = data.answer\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.65,test_size=0.35)\n",
        "\n",
        "def tokenize():\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(list(X_train))\n",
        "  X_train_seq  = tokenizer.texts_to_sequences(X_train) \n",
        "  X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "  X_train_seq  = pad_sequences(X_train_seq, maxlen=100)\n",
        "  X_test_seq = pad_sequences(X_test_seq, maxlen=100)\n",
        "  y_train_seq  = tokenizer.texts_to_sequences(y_train) \n",
        "  y_test_seq = tokenizer.texts_to_sequences(y_test)\n",
        "  y_train_seq  = pad_sequences(y_train_seq, maxlen=100)\n",
        "  y_test_seq = pad_sequences(y_test_seq, maxlen=100)\n",
        "  return X_train_seq, X_test_seq, y_train_seq, y_test_seq\n",
        "\n",
        "X_train_seq, X_test_seq, y_train_seq, y_test_seq = tokenize()\n",
        "\n",
        "#print(\"X_train_seq\", X_train_seq)\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X_train_seq.shape[0], X_train_seq.shape[1]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]\n",
        "model.fit(X, y, epochs=4, batch_size=256, callbacks=desired_callbacks)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "predictions = model.predict(X_train_seq)\n",
        "#print(predictions)\n",
        "#print(y_train_seq)\n",
        "y1=lb.inverse_transform(predictions)\n",
        "#print(y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4tpKLAxKEB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "  \n",
        "df = getDF('/content/sample_data/qa_Appliances.json.gz')\n",
        "#df = df.drop(['questionType', 'asin', 'answerTime', 'unixTime','answerType'], axis = 1)\n",
        "a = df.to_csv('/content/sample_data/appliances.csv')\n",
        "data = pd.read_csv(\"/content/sample_data/appliances.csv\") \n",
        "\n",
        "def display_char_vocab(data):\n",
        "  chars = sorted(list(set(data)))\n",
        "  char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "  n_chars = len(data)\n",
        "  n_vocab = len(chars)\n",
        "  return n_chars, n_vocab\n",
        "\n",
        "seq_length = 100\n",
        "#h = df.head()\n",
        "#print(h)\n",
        "#print(df.columns)\n",
        "y = data.question\n",
        "X = data.answer\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.65,test_size=0.35)\n",
        "\n",
        "def tokenize():\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(list(X_train))\n",
        "  X_train_seq  = tokenizer.texts_to_sequences(X_train) \n",
        "  X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "  X_train_seq  = pad_sequences(X_train_seq, maxlen=100)\n",
        "  X_test_seq = pad_sequences(X_test_seq, maxlen=100)\n",
        "  y_train_seq  = tokenizer.texts_to_sequences(y_train) \n",
        "  y_test_seq = tokenizer.texts_to_sequences(y_test)\n",
        "  y_train_seq  = pad_sequences(y_train_seq, maxlen=100)\n",
        "  y_test_seq = pad_sequences(y_test_seq, maxlen=100)\n",
        "  return X_train_seq, X_test_seq, y_train_seq, y_test_seq\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "X_train_seq, X_test_seq, y_train_seq, y_test_seq = tokenize()\n",
        "#print(\"X_train_seq\", X_train_seq)\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X_train_seq.shape), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]\n",
        "model.fit(X, y, epochs=4, batch_size=256, callbacks=desired_callbacks)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "predictions = model.predict(X_test_seq)\n",
        "#print(predictions)\n",
        "#print(y_train_seq)\n",
        "y1=lb.inverse_transform(predictions)\n",
        "#print(y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLjxPbIy5lFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "ed84393b-859d-47f6-e1e0-4129e5bdc579"
      },
      "source": [
        "print(df.head)\n",
        "print(len(df['question']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                                                question                                             answer\n",
            "0     I have a 9 year old Badger 1 that needs replac...   I replaced my old one with this without a hitch.\n",
            "1                                          model number  This may help InSinkErator Model BADGER-1: Bad...\n",
            "2     can I replace Badger 1 1/3 with a Badger 5 1/2...  Plumbing connections will vary with different ...\n",
            "3     Does this come with power cord and dishwasher ...  It does not come with a power cord. It does co...\n",
            "4     loud noise inside when turned on. sounds like ...  Check if you dropped something inside.Usually ...\n",
            "...                                                 ...                                                ...\n",
            "9006         How come it is compatible with all brands?  The Woder 5K Inline Water Filter for Ice ice m...\n",
            "9007  Is it compatible to replace my Maytag UKF8001 ...  Yes, of course. The Woder Fridge Filter fits b...\n",
            "9008  I cannot find any official reference to testin...  'Woder' is a Clearbrook LLC / Sunrise Solution...\n",
            "9009  Can it be installed inside the refrigerator, a...  I can't say for certain but it would require c...\n",
            "9010  I just got the filter in and it doesn't look l...  You have received the correct filter. They hav...\n",
            "\n",
            "[9011 rows x 2 columns]>\n",
            "9011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZ3UjDGAWJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}